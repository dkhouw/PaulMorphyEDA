{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec977ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import csv\n",
    "\n",
    "# Objective: To scrape Paul Morphy's chess games on chess.com, sectioned off into white games and black games.\n",
    "# Will then use the scraped data to clean, feature engineer, make visualizations and light exploratory analysis with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88467884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type in URL:https://www.chess.com/games/search?p1=paul-morphy&sort=4\n",
      "Here we go!\n"
     ]
    }
   ],
   "source": [
    "URL = input('Type in URL:')\n",
    "print('Here we go!')\n",
    "# 'https://www.chess.com/games/search?p1=paul-morphy&sort=3' # white games\n",
    "# 'https://www.chess.com/games/search?p1=paul-morphy&sort=4' # black games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb739624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name your csv file:blackgames\n"
     ]
    }
   ],
   "source": [
    "# Get the players names and their ratings if available\n",
    "def get_players(game):\n",
    "    users = game.find_all('span', class_= {'master-games-username', 'master-games-user-rating'})\n",
    "    n = len(users)\n",
    "    if n > 3:\n",
    "        p1, p1_rating, p2, p2_rating = users\n",
    "        return p1.string + \" \" + p1_rating.string + \" \" + p2.string + \" \" + p2_rating.string\n",
    "    else:\n",
    "        p1, p1_rating, p2 = users\n",
    "        return p1.string + \" \" + p1_rating.string + \" \" + p2.string\n",
    "\n",
    "# Get the opening moves and opening name as well as the varation if available\n",
    "def get_opening(game):\n",
    "    opening = game.find('a', class_='master-games-content-stats master-games-opening')\n",
    "    opening_moves = opening['title']\n",
    "    opening_name = opening.contents[3].string.lstrip()\n",
    "    return opening_moves + \" \" + opening_name\n",
    "\n",
    "# Get the result of the game\n",
    "def get_result(game):\n",
    "    result = game.find('a', class_= 'master-games-clickable-link master-games-text-middle').string.strip()\n",
    "    return result\n",
    "\n",
    "# Get the number of moves of the game\n",
    "def get_num_moves(game):\n",
    "    num_moves = game.find_all('a', class_= 'master-games-clickable-link master-games-text-middle')[1]\n",
    "    num_moves = num_moves.text.strip()\n",
    "    return num_moves\n",
    "\n",
    "# Get the year the game was played\n",
    "def get_year(game):\n",
    "    year = game.find('a', class_=\"master-games-date master-games-clickable-link master-games-text-middle\")['title']\n",
    "    return year\n",
    "\n",
    "rows = []\n",
    "header = ['Players', 'Opening', 'Result', 'Moves', 'Year'] # column names\n",
    "\n",
    "# Scrape all the games from every page into a lists of lists\n",
    "def scrape(url):\n",
    "    current_page = 1\n",
    "    \n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    max_pages = int(soup.find(id=\"master-games-container\")['data-total-pages'])\n",
    "    \n",
    "    while current_page <= max_pages:\n",
    "        current_url = url + '&page=' + str(current_page)\n",
    "        html = requests.get(current_url)\n",
    "        soup = BeautifulSoup(html.content, 'html.parser')\n",
    "        games = soup.find_all(\"tr\", class_=\"master-games-master-game v-board-popover\")\n",
    "        for game in games:\n",
    "            rows.append([get_players(game),\n",
    "                        get_opening(game),\n",
    "                        get_result(game),\n",
    "                        get_num_moves(game),\n",
    "                        get_year(game)])\n",
    "        current_page += 1\n",
    "        time.sleep(5)\n",
    "    return rows\n",
    "\n",
    "rows = scrape(URL)\n",
    "name_of_csv = input('Name your csv file! White or black?')\n",
    "with open(name_of_csv.lower() + 'games.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow(header)\n",
    "    csvwriter.writerows(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1b97e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
